Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,1.4189384,-0.016824553,98.24242424242425,-0.8878319484929582,-0.8878319484929582,1.0
20000,1.419269,-0.033940762,173.12698412698413,-0.9006940240099554,-0.9006940240099554,1.0
30000,1.4190755,-0.05145873,293.03125,-0.9247217970696511,-0.9247217970696511,1.0
40000,1.4170825,-0.043720786,354.5,-0.3546827923564706,-0.3546827923564706,1.0
50000,1.4154292,-0.007023279,199.0909090909091,-0.6931958612774245,-0.6931958612774245,1.0
60000,1.4150546,0.008731811,1023.4117647058823,0.563287802535342,0.563287802535342,1.0
70000,1.4148748,0.033133525,212.0,0.11133926319466396,0.11133926319466396,1.0
