Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,1.4189384,-0.000321402,735.0,0.8741717748343945,0.8741717748343945,1.0
20000,1.4226342,0.028754408,1404.0,2.8304491974413395,2.8304491974413395,1.0
30000,1.4236549,0.060550462,1385.0,2.6986073162406683,2.6986073162406683,1.0
40000,1.4255921,0.08742429,2967.0,7.147501558065414,7.147501558065414,1.0
50000,1.427873,0.109973006,3157.0,7.6931814551353455,7.6931814551353455,1.0
60000,1.4316922,0.12986478,None,None,None,1.0
70000,1.4348066,0.15352349,None,None,None,1.0
80000,1.4380955,0.1860636,None,None,None,1.0
90000,1.4404645,0.22150724,None,None,None,1.0
100000,1.4424447,0.2603131,5568.0,23.02189464867115,23.02189464867115,1.0
110000,1.4432935,0.30672452,None,None,None,1.0
120000,1.4421134,0.3566223,None,None,None,1.0
130000,1.4404708,0.41210744,12232.0,56.373311545699835,56.373311545699835,1.0
140000,1.4399089,0.46741825,14295.0,73.53481668233871,73.53481668233871,1.0
150000,1.4392933,0.5235036,753.0,6.925425231456757,6.925425231456757,1.0
160000,1.4385281,0.5857074,None,None,None,1.0
170000,1.437183,0.64876443,None,None,None,1.0
180000,1.4342468,0.7104911,None,None,None,1.0
190000,1.4311355,0.77150697,None,None,None,1.0
200000,1.4280015,0.830484,None,None,None,1.0
210000,1.4249064,0.8869742,None,None,None,1.0
220000,1.4227037,0.9430516,None,None,None,1.0
230000,1.4200556,0.99761826,None,None,None,1.0
240000,1.4167718,1.0481266,None,None,None,1.0
250000,1.4127768,1.096884,None,None,None,1.0
260000,1.409124,1.1450068,None,None,None,1.0
270000,1.4057075,1.1912259,None,None,None,1.0
280000,1.4023763,1.2376453,31131.0,287.17710392177105,287.17710392177105,1.0
